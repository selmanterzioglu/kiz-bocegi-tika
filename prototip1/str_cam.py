# Pylon/PyPylon;
# - https://github.com/basler/pypylon
# - https://www.pythonforthelab.com/blog/getting-started-with-basler-cameras/
# 

# BUILT-IN LIBRARIES
#import threading
from enum import Enum
from time import sleep
import logging

# EXTERNAL LIBRARIES
import cv2
# from ordered_enum import OrderedEnum

# CUSTOM LIBRARIES
import neoapi_libs
from stdo import stdo
# from structure_data import structure_buffer
from structure_threading import Thread_Object
from structure_data import Structure_Buffer
from tools import time_log, time_list, TIME_FLAGS, get_OS

# Camera Instance Flags
class CAMERA_FLAGS(Enum):
    CV2 = 0
    BAUMER = 1
    BASLER = 2
    ARDUCAM = 3


class Camera_Object():
    __camera_Object_Counter = 0
    '''
    This code is a class that will be used to control the camera. It has two main functions, initialize and acquire_image.
    The first function initializes the camera with all of its settings. The second function acquires an image from the camera using either software or hardware trigger depending on what flag was set when creating this object.
    - generated by stenography autopilot 
    '''

    def __init__(
            self, 
            camera_flag=CAMERA_FLAGS.BAUMER, 
            index_device=0,
            logger_level=logging.INFO, 
            auto_configure=True, 
            extra_params=[],
            trigger_pause=None,
            trigger_quit=None, 
            lock_until_done=True, 
            max_buffer_limit=1, 
            exposure_time=60000, 
            acquisition_framerate_enable=True, 
            acquisition_framerate=25,
            is_auto_detect=False
        ):
        self.__thread_Dict = dict()
        self.__instance_Exit_Statement = False
        self.is_Auto_Detecting = False
        self.__buffer_Stream = Structure_Buffer(max_limit=max_buffer_limit)

        self.instance_Camera = None
        self.verbose_level = None
        self.is_Camera_Initialized = False
        self.is_Object_Initialized = True
        self.last_Snapshot = None
        self.camera_Last_Statement = False
        self.fps_time = -1
        
        self.index_device = index_device
        self.auto_configure = auto_configure
        self.extra_params=extra_params
        self.exposure_time = exposure_time
        self.acquisition_framerate_enable = acquisition_framerate_enable
        self.acquisition_framerate = acquisition_framerate

        if camera_flag not in CAMERA_FLAGS._value2member_map_.values():
            #self.logger.error(
            stdo(3, "Non Compatible Camera Flag Error: {}".format(camera_flag))
            # self.quit()
            self.__del__()
            return None
        self.flag_Camera = camera_flag
        
        Camera_Object.__camera_Object_Counter += 1
        self.instance_id = Camera_Object.__camera_Object_Counter

        self.name = "Camera_Object {}-{}".format(
            self.flag_Camera.name,
            self.instance_id
        )

        self.logger = logging.getLogger(self.name)

        # https://stackoverflow.com/questions/3220284/how-to-customize-the-time-format-for-python-logging
        # self.logger.setLevel(logging.NOTSET)
        handler = logging.StreamHandler()
        # formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        formatter = logging.Formatter(
            '[%(asctime)s][%(levelname)s] %(name)s : %(message)s',
            "%Y-%m-%d %H:%M:%S"
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.setLevel(logger_level)
        

        if is_auto_detect:
            self.flag_Camera = self.auto_detect(
                trigger_quit=trigger_quit, 
                trigger_pause=trigger_pause, 
                delay=0.1
            )
        
        # Decide if auto init or not
        self.initialize(
            auto_configure=self.auto_configure,
            extra_params=self.extra_params,
            index_device=self.index_device,
            trigger_quit=trigger_quit, 
            trigger_pause=trigger_pause,
            lock_until_done=lock_until_done, 
            exposure_time=self.exposure_time,
            acquisition_framerate_enable=self.acquisition_framerate_enable, 
            acquisition_framerate=acquisition_framerate
        )
        self.resolution = self.get_Camera_Size()

    '''
    This code is creating a class that will be used to create objects of the camera.
    The __init__ method is called when an object of this class is created and it takes in two parameters, self and args.
    self refers to the current instance of the object being created. 
    args are arguments passed into the function when it was called from another function or program. 
    In this case, we have no arguments so we pass None as an argument for args.
    - generated by stenography autopilot 
    '''
    @classmethod

    def __len__(cls):
        # https://www.programiz.com/python-programming/methods/built-in/len
        # https://stackoverflow.com/questions/13012159/how-create-a-len-function-on-init
        # return self.__len__()
        return cls.__camera_Object_Counter

    '''
    This code is initializing the camera object.
    - generated by stenography autopilot 
    '''

    def __del__(self):
        self.is_Object_Initialized = False
        """
        self.logger.info(
            "Camera Object {}-{} Destroyed.".format(
                self.flag_Camera,
                Camera_Object.__camera_Object_Counter
            )
        )
        """

    # ### ## ### #
    # CLASS APIs #
    # ### ## ### #

    '''
    This code creates a new camera instance. Then, it connects to the camera and sets up all configurations.
    Then, it starts acquisition if needed (if not already started). Finally, it waits until the acquisition is done or aborted by user.
    Finally, it disconnects from the camera and releases its resources.
    - generated by stenography autopilot 
    '''

    def initialize(
        self,
        index_device = 0,
        auto_configure=True, 
        extra_params=[],
        trigger_pause=None, 
        trigger_quit=None, 
        lock_until_done=True, 
        exposure_time=60000, 
        acquisition_framerate_enable=True, 
        acquisition_framerate=25
    ):
        self.logger.info("Camera Initializing...")

        if trigger_pause is None or not callable(trigger_pause):
            trigger_pause = self.trigger_pause()
                
        if self.flag_Camera is CAMERA_FLAGS.BAUMER:
            self.api_Baumer_Camera_Create_Instance()
            
        elif self.flag_Camera is CAMERA_FLAGS.BASLER:
            self.api_Basler_Camera_Create_Instance()

        elif self.flag_Camera is CAMERA_FLAGS.ARDUCAM:
            self.api_Arducam_Camera_Create_Instance()
            
        elif self.flag_Camera is CAMERA_FLAGS.CV2:
            self.api_CV2_Camera_Create_Instance(
                index_device, 
                extra_params=extra_params
            )
            #self.api_CV2_Camera_Create_Instance(Camera_Object.__camera_Object_Counter)

        # is_Camera_Initialized = (False or True) is done in initialize function
        # Do Not handle not initialized scenario!
        if self.connect() is True:
            if auto_configure:
                if self.flag_Camera is CAMERA_FLAGS.BAUMER:
                    self.api_Baumer_Camera_Is_Colorful()
                    self.api_Baumer_Camera_Configurations(
                        exposure_time=exposure_time, 
                        acquisition_framerate_enable=acquisition_framerate_enable, 
                        acquisition_framerate=acquisition_framerate
                    )
                    
                elif self.flag_Camera is CAMERA_FLAGS.BASLER:
                    self.api_Basler_Camera_Configurations(
                        exposure_time=exposure_time, 
                        acquisition_framerate_enable=acquisition_framerate_enable, 
                        acquisition_framerate=acquisition_framerate
                    )

                elif self.flag_Camera is CAMERA_FLAGS.ARDUCAM:
                    self.logger.warning(f"No configuration appointed for {self.flag_Camera.name} camera instance. Nothing done...")
                    
                elif self.flag_Camera is CAMERA_FLAGS.CV2:
                    self.logger.warning(f"No configuration appointed for {self.flag_Camera.name} camera instance. Nothing done...")

        if lock_until_done and not self.is_Camera_Active():
            self.logger.info("Camera Initializing failed! Calling recovery...")
            self.camera_Recovery(trigger_quit=trigger_quit, trigger_pause=trigger_pause)
            self.camera_Last_Statement = True

    '''
    This code is checking if the camera has been initialized. If it hasn\'t, then it will initialize the camera and set self.is_Camera_Initialized to True.
    If the camera has already been initialized, then this code will check if there\'s a flag for that specific camera in CAMERA_FLAGS (defined below).
    If there isn\'t one, then it will skip over that iteration of the loop and move on to the next iteration of the loop.
    - generated by stenography autopilot 
    '''

    def auto_detect(self, trigger_quit=None, trigger_pause=None, delay=0.1):
        stdo(2, "Still at Development...")
        """
        stdo(1, "Auto Detecting...")
        
        if trigger_pause is None or not callable(trigger_pause):
            trigger_pause = self.trigger_pause()
            
        self.is_Auto_Detecting = True
        while not trigger_quit() and trigger_pause() and self.is_Auto_Detecting:
            sleep(delay)
            if trigger_pause:
                continue
            
            for camera_flag in CAMERA_FLAGS:
                self.flag_Camera = camera_flag
                self.is_Camera_Initialized = self.connect()
                
            if self.is_Camera_Initialized:
                self.is_Auto_Detecting = False
        stdo(1, "Auto Detected.")
        """

    '''
    This code is initializing the camera. Then, it is starting a thread for each of the cameras. The threads are responsible for acquiring images from the camera and putting them in a buffer.
    - generated by stenography autopilot 
    '''

    def quit(self):
        self.logger.info("Exiting from camera {}-{} ...".format(
            self.flag_Camera, self.instance_id))
        
        camera_release_result = self.camera_Releaser()
        if camera_release_result == 0:
            self.logger.info("Camera released.")
        else:
            self.logger.error("Camera Release Error {}".format(camera_release_result))
        self.__instance_Exit_Statement = True
        self.logger.info("Buffer cleaned. {} number of buffer element removed.".format(len(self.buffer_Clear())))
        
        for thread_id, thread in self.__thread_Dict.items():
            thread.statement_quit = True
            self.logger.info("Thread {}:{} stopped.".format(thread_id, thread.name))
        self.__thread_Dict.clear()
        
        self.__del__()

    def trigger_pause(self):
        return False

    def undistort(self):
        self.logger.info("Still at development...")

    # ### ## ### #
    # ### ## ### #
    # ### ## ### #

    # ### ### ### #
    # CAMERA APIs #
    # ### ### ### #

    '''
    This code is doing the following things.
        1) Connect to the camera using pylon API.
        2) Initialize a logger instance for logging purposes.
        3) Check if the camera is connected and initialized successfully or not, by checking self.is_Camera_Initialized flag value which will be set to True/False based on success of connection with Camera device.
    - generated by stenography autopilot 
    '''

    def connect(self):
        try:
            if self.flag_Camera is CAMERA_FLAGS.BAUMER:
                self.instance_Camera.Connect() if self.instance_Camera is not None else None
                self.logger.info("Camera Instance is Successful, The Instance is {}".format(
                    self.instance_Camera))
            elif self.flag_Camera is CAMERA_FLAGS.BASLER:
                self.instance_Camera.StartGrabbing(
                    pylon.GrabStrategy_LatestImageOnly
                ) if self.instance_Camera is not None else None
                self.logger.info(
                    "Camera Instance is Successful, The Instance is {}".format(
                        self.instance_Camera
                    )
                )
            elif self.flag_Camera is CAMERA_FLAGS.CV2:
                self.logger.warning(
                    f"No need to connect {self.flag_Camera} camera instance. Nothing done..."
                )
            self.is_Camera_Initialized = True
        # except neoapi.NotConnectedException as error:
        #     self.logger.error(
        #         f"{self.flag_Camera} Camera No Device NotConnectedException: {error}"
        #     )
        #     self.is_Camera_Initialized = False
        # except neoapi.FeatureAccessException as error:
        #     self.logger.error(
        #         f"{self.flag_Camera} Camera No Device FeatureAccessException: {error}"
        #     )
        #     self.is_Camera_Initialized = False
        except Exception as error:
            self.logger.error(
                f"{self.flag_Camera} Camera Connect: {error}"
            )
            self.is_Camera_Initialized = False

        return self.is_Camera_Initialized

    def snapshot(self, is_buffer_enabled=True):
        is_Successful = False
        local_Last_Snapshot = None

        time_log(self.name, flag=TIME_FLAGS.START)
        if self.flag_Camera is CAMERA_FLAGS.BAUMER:

            '''
            This code is checking if the camera has been initialized. If it hasn\'t, then we don\'t want to try and get a snapshot from the camera.
            If it has been initialized, then we do want to try and get a snapshot from the camera. We also need to check that there was no error getting the image from the camera (i.e., not None).
            - generated by stenography autopilot 
            '''
            try:
                time_log(id=repr(CAMERA_FLAGS.BAUMER))
                local_Last_Snapshot = self.instance_Camera.GetImage().GetNPArray() if self.instance_Camera is not None else None
                time_log(id=repr(CAMERA_FLAGS.BAUMER))
                self.logger.debug(
                    "{} Time passed: {:.3f} ms".format(
                        repr(CAMERA_FLAGS.BAUMER),
                        time_list[repr(CAMERA_FLAGS.BAUMER)][TIME_FLAGS.PASSED]
                    )
                )
                if local_Last_Snapshot is not None:
                    if len(local_Last_Snapshot) != 0:
                        self.logger.debug(
                            "snapshot get successful frame!"
                        )
                        is_Successful = True
                    else:
                        self.logger.debug(
                            "snapshot get unsuccessful frame (0 length)!"
                        )
                        is_Successful = False
                else:
                    self.logger.debug(
                        "snapshot get unsuccessful frame (None)!"
                    )
                    is_Successful = False

            except neoapi.NotConnectedException as error:
                self.logger.error(
                    f"{self.flag_Camera} Camera NotConnectedException: {error}"
                )
                is_Successful = False
            except Exception as error:
                self.logger.error(
                    f"{self.flag_Camera} Camera Get Snapshot Error: {error}"
                )
                is_Successful = False

            #if self.is_Camera_Initialized == False:
            #    is_Successful = False

        elif self.flag_Camera is CAMERA_FLAGS.BASLER:

            '''
            This code is initializing the camera.
            Then, it is grabbing a frame from the camera and converting it to an image.
            Finally, this code will save that image as a jpg file in the directory specified by `self.snapshot_path`.
            - generated by stenography autopilot 
            '''
            try:
                time_log(id=repr(CAMERA_FLAGS.BASLER), flag=TIME_FLAGS.START)

                if self.instance_Camera is not None:
                    if self.instance_Camera.IsGrabbing():
                        local_Last_Snapshot = self.instance_Camera.RetrieveResult(
                            5000, pylon.TimeoutHandling_ThrowException)
                        if local_Last_Snapshot.GrabSucceeded():
                            #if hasattr(self, "converter"):
                            local_last_snapshot_converted = self.converter.Convert(
                                local_Last_Snapshot
                            ).GetArray()
                        else:
                            self.logger.debug("BASLER Camera Grab is NOT succeed!")
                            local_last_snapshot_converted = None
                            is_Successful = False
                        local_Last_Snapshot.Release()
                        local_Last_Snapshot = local_last_snapshot_converted
                    else:
                        self.logger.debug("BASLER Camera is NOT Grabbing!")
                        is_Successful = False

                time_log(id=repr(CAMERA_FLAGS.BASLER), flag=TIME_FLAGS.END)
                self.logger.debug("{} Time passed: {:.3f} ms".format(
                        repr(CAMERA_FLAGS.BASLER),
                        time_list[repr(CAMERA_FLAGS.BASLER)][TIME_FLAGS.PASSED]
                    )
                )
                """
                # debug:
                stdo(1, "{} Time passed: {:.3f} ms".format(
                        repr(CAMERA_FLAGS.BASLER),
                        time_list[repr(CAMERA_FLAGS.BASLER)][TIME_FLAGS.PASSED]
                    )
                )
                """
                if local_Last_Snapshot is not None:
                    if len(local_Last_Snapshot) != 0:
                        self.logger.debug("snapshot get successful frame!")
                        is_Successful = True
                    else:
                        self.logger.debug(
                            "snapshot get unsuccessful frame (0 length)!")
                        is_Successful = False
                else:
                    self.logger.debug(
                        "snapshot get unsuccessful frame (None)!")
                    is_Successful = False

            except Exception as error:
                self.logger.error(
                    f"{self.flag_Camera} Camera Get Snapshot Error: {error}"
                )
                is_Successful = False
                if local_Last_Snapshot is not None:
                    local_Last_Snapshot.Release()

        elif self.flag_Camera is CAMERA_FLAGS.CV2:
            # cap.open(0, cv::CAP_DSHOW)
            # Returns (False, None) in fail, (True, image) otherwise

            '''
            This code is doing the following things.
                1) Reads a frame from the camera and stores it in local_Last_Snapshot variable.
                2) If read was successful, then returns True else False.
            - generated by stenography autopilot 
            '''
            if self.instance_Camera is not None:
                is_Successful, local_Last_Snapshot = self.instance_Camera.read()
            else:
                is_Successful, local_Last_Snapshot = False, None
            
            ##############################################
            # TODO: REMOVE #
            # if is_Successful:
            #    print("h-w:", local_Last_Snapshot.shape)
            ##############################################
            
            #is_Successful, local_Last_Snapshot = True, None

            # TODO: At connection lost, re-initialize (camera recovery) is not working. Someone sad to use grab+retrieve instead of read which read does both and gives decoded frame rather than 2 step. Just try it!
            # https://answers.opencv.org/question/21069/cant-grab-frame-from-webcamera/
            # https://stackoverflow.com/questions/57716962/difference-between-video-capture-read-and-grab
            # cap.grab();
            # cap.retrieve(&frame, 0);

        '''
        This code is appending the last snapshot to a buffer.
        The buffer is used for training and testing purposes.
        This code will be executed only if the flag `is_buffer_enabled` is set to True, which means that we are in train or test mode.
        - generated by stenography autopilot 
        '''

        if is_buffer_enabled and is_Successful:
            #print(local_Last_Snapshot.shape, type(local_Last_Snapshot), self.camera_pack)
            #cv2.imshow("TP", cv2.resize(local_Last_Snapshot,None,fx=0.2,fy=0.2))
            self.__buffer_Stream.append(local_Last_Snapshot)
        time_log(self.name, flag = TIME_FLAGS.END)

        if time_list[self.name][TIME_FLAGS.PASSED] != 0:
            self.fps_time = 60000 / time_list[self.name][TIME_FLAGS.PASSED]
        self.last_Snapshot = local_Last_Snapshot
        self.last_is_successful = is_Successful

        return is_Successful, local_Last_Snapshot

    '''
    This code is starting a thread that will run the stream_Start function.
    The parameters are passed to the stream_Start function as an array of arguments.
    This allows for multiple threads to be started and each one can have its own set of arguments.
    The task parameter tells the thread what it should do when it runs, in this case we want to call our camera\'s start streaming method.
    - generated by stenography autopilot 
    '''

    def stream_Start_Thread(self, trigger_pause=None, trigger_quit=None, number_of_snapshot=-1, delay=0.001, trigger_before=None, trigger_after=None):
        if self.get_Is_Object_Initialized():
            self.__thread_Dict["stream_Start_Thread"] = Thread_Object(
                name="Camera_Object.stream_Start_Thread",
                delay=0.0001,
                logger_level=self.logger.getEffectiveLevel(),
                set_Daemon=True,
                run_number=1,
                quit_trigger=trigger_quit
            )
            self.__thread_Dict["stream_Start_Thread"].init(
                params=[
                    trigger_pause,
                    trigger_quit,
                    number_of_snapshot,
                    delay,
                    trigger_before, 
                    trigger_after
                ],
                task=self.stream_Start
            )
            self.__thread_Dict["stream_Start_Thread"].start()

            return self.__thread_Dict["stream_Start_Thread"]
        else:
            return None

    def stream_And_Save_Start_Thread(self, trigger_pause=None, trigger_quit=None, number_of_snapshot=-1, delay=0.001, trigger_before=None, trigger_after=None, save_path="video.avi", fps=24):
        if self.get_Is_Object_Initialized():
            self.__thread_Dict["stream_And_Save_Start_Thread"] = Thread_Object(
                name="Camera_Object.stream_And_Save_Start_Thread",
                delay=0.0001,
                logger_level=self.logger.getEffectiveLevel(),
                set_Daemon=True,
                run_number=1,
                quit_trigger=trigger_quit
            )
            self.__thread_Dict["stream_And_Save_Start_Thread"].init(
                params=[
                    trigger_pause,
                    trigger_quit,
                    number_of_snapshot,
                    delay,
                    trigger_before,
                    trigger_after,
                    save_path,
                    fps
                ],
                task=self.stream_Start_And_Save
            )
            self.__thread_Dict["stream_And_Save_Start_Thread"].start()

            return self.__thread_Dict["stream_And_Save_Start_Thread"]
        else:
            return None

    '''
    This code is creating a thread that will start the stream.
    The code block has two parameters, trigger_pause and trigger_quit. These are triggers to pause or quit the video recording process.
    trigger_pause is used to pause the video recording process when it\'s running in another thread.
    trigger_quit is used to stop the video recording process when it\'s running in another thread.
    - generated by stenography autopilot 
    '''

    def save_Video_From_Buffer_Thread(self, path="", name="capture", codec="MJPG", extension="avi", fps=24, trigger_pause=None, trigger_quit=None, number_of_snapshot=-1, delay=0.001):
        if self.get_Is_Object_Initialized():
            self.__thread_Dict["save_Video_Start_Thread"] = Thread_Object(
                name="Camera_Object.save_Video_Start_Thread",
                delay=0.0001,
                logger_level=self.logger.getEffectiveLevel(),
                set_Daemon=True,
                run_number=1,
                quit_trigger=trigger_quit
            )
            self.__thread_Dict["save_Video_Start_Thread"].init(
                params=[
                    path,
                    name, 
                    codec, 
                    extension,
                    fps,
                    trigger_pause,
                    trigger_quit,
                    number_of_snapshot,
                    delay
                ],
                task=self.save_Video_From_Buffer
            )
            self.__thread_Dict["save_Video_Start_Thread"].start()

            return self.__thread_Dict["save_Video_Start_Thread"]
        else:
            return None
    
    '''
    This code is taking the image from buffer and writing it to a video file.
    - generated by stenography autopilot 
    '''

    def save_Video_From_Buffer(self, path="", name="capture", codec="MJPG", format="avi", fps=24, trigger_pause=None, trigger_quit=None, number_of_frame=-1, delay=0.001):
        if trigger_pause is None or not callable(trigger_pause):
            trigger_pause = self.trigger_pause

        pause_Delay = 0.1
        size = self.get_Camera_Size()
        
        # Below VideoWriter object will create
        # a frame of above defined The output 
        # is stored in (path + "." +  format) file.

        out_file = cv2.VideoWriter(
            path + name + "." +  format, 
            cv2.VideoWriter_fourcc(*codec),
            fps, size
        )
        while number_of_frame != 0:
            if trigger_pause():
                # if not self.is_Same_Image(last_image, current_image):
                #     out_file.write(current_image)
                out_file.write(self.stream_Returner())

                # last_image = current_image

                if number_of_frame > 0:
                    number_of_frame -= 1

            else:
                self.logger.debug(
                    "save_Video_From_Buffer get trigger_pause. Waiting {} sec.".format(
                        pause_Delay
                    )
                )
                sleep(pause_Delay)

            if trigger_quit is not None:
                if trigger_quit():
                    self.logger.debug(
                        "save_Video_From_Buffer quit trigger activated! Quitting..."
                    )
                    break
            elif self.__instance_Exit_Statement:
                self.logger.debug("{}-{} Camera Instance save_Video_From_Buffer Exit Statement activated! Quitting...".format(
                        self.flag_Camera,
                        self.instance_id
                    )
                )
                break
        out_file.release()
        return 0

    def get_Camera_Size(self):
        if self.instance_Camera is not None:
            # TODO: Add Camera Size Property for Baumer and Basler Camera APIs  
            if self.flag_Camera is CAMERA_FLAGS.BAUMER:
                width  = 0.0 # float `width`
                height = 0.0 # float `height`

            elif self.flag_Camera is CAMERA_FLAGS.BASLER:
                width  = 0.0 # float `width`
                height = 0.0 # float `height`

            elif self.flag_Camera is CAMERA_FLAGS.CV2:
                # https://stackoverflow.com/questions/39953263/get-video-dimension-in-python-opencv/39953739
                width = self.instance_Camera.get(
                    cv2.CAP_PROP_FRAME_WIDTH
                )   # float `width`
                height = self.instance_Camera.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`
            else:
                width  = 0.0 # float `width`
                height = 0.0 # float `height`
        else:   
            width  = 0.0 # float `width`
            height = 0.0 # float `height`
        return int(width), int(height)

    '''
    This code is checking if the camera is active. If not, it will call a function to recover the camera and then start streaming again.
    If the camera is active, it will check if there are any snapshots in buffer. If so, it will take one snapshot from buffer and return that frame as result of this function.
    Otherwise, it will wait for a while before taking another snapshot (delay). It also checks if there\'s quit trigger or pause trigger set by user when calling stream_Start(). If yes, then we\'ll exit from thread with appropriate message.
    - generated by stenography autopilot 
    '''

    def stream_Start_And_Save(self, trigger_pause=None, trigger_quit=None, number_of_snapshot=-1, delay=0.001, trigger_before=None, trigger_after=None, save_path="", fps=24):
        if trigger_pause is None or not callable(trigger_pause):
            trigger_pause = self.trigger_pause

        if save_path:
            size = (640, 480)
            out_file = cv2.VideoWriter(
                save_path,
                cv2.VideoWriter_fourcc(*'XVID'),
                20.0, size
            )
        else:
            out_file = None

        pause_Delay = 1
        while number_of_snapshot != 0:
            if trigger_pause():
                if not self.is_Camera_Active():
                    self.logger.debug(
                        "stream_Start get Camera NOT Active. 'camera_Recovery' calling...")
                    self.camera_Recovery(
                        trigger_quit=trigger_quit,
                        trigger_pause=trigger_pause
                    )
                # (self.instance_Camera is None) Means we got quit trigger from camera recovery function, thus quit from thread.
                if self.instance_Camera is None:
                    self.logger.debug(
                        "stream_Start get instance_Camera as None caused by active quit trigger. Quitting..."
                    )
                    break

                if trigger_before is not None and callable(trigger_before):
                    trigger_before()
                is_Successful, snapshot = self.snapshot(is_buffer_enabled=True)
                if trigger_after is not None and callable(trigger_after):
                    trigger_after(snapshot)

                if not is_Successful:
                    self.logger.debug(
                        "stream_Start get NOT successful frame. 'camera_Recovery' calling...")
                    self.camera_Recovery(
                        trigger_quit=trigger_quit,
                        trigger_pause=trigger_pause
                    )

                if save_path and out_file is not None:
                    out_file.write(snapshot)
                    
                if number_of_snapshot > 0:
                    number_of_snapshot -= 1
            else:
                self.logger.debug(
                    "stream_Start get trigger_pause. Waiting {} sec.".format(
                        pause_Delay)
                )
                sleep(pause_Delay)

            if trigger_quit is not None and not self.__instance_Exit_Statement:
                if trigger_quit():
                    self.logger.debug(
                        "stream_Start quit trigger activated! Quitting..."
                    )
                    break
            elif self.__instance_Exit_Statement:
                self.logger.debug("{}-{} Camera Instance stream_Start Exit Statement activated! Quitting...".format(
                        self.flag_Camera,
                        self.instance_id
                    )
                )
                break
            # stdo(1, "Buffer: {}".format(len(self.__buffer_Stream)))
            sleep(delay)

        if save_path and out_file is not None:
            out_file.release()
        self.quit()
        return 0


    def stream_Start(self, trigger_pause=None, trigger_quit=None, number_of_snapshot=-1, delay=0.001, trigger_before=None, trigger_after=None):
        if trigger_pause is None or not callable(trigger_pause):
            trigger_pause = self.trigger_pause

        pause_Delay = 1
        while number_of_snapshot != 0:
            if trigger_pause():
                if not self.is_Camera_Active():
                    self.logger.debug(
                        "stream_Start get Camera NOT Active. 'camera_Recovery' calling...")
                    self.camera_Recovery(
                        trigger_quit=trigger_quit, 
                        trigger_pause=trigger_pause
                    )
                # (self.instance_Camera is None) Means we got quit trigger from camera recovery function, thus quit from thread.
                if self.instance_Camera is None:
                    self.logger.debug(
                        "stream_Start get instance_Camera as None caused by active quit trigger. Quitting..."
                    )
                    return 0  # break # Lets make it clear at quit statement

                if trigger_before is not None and callable(trigger_before):
                    trigger_before()
                is_Successful, snapshot = self.snapshot(is_buffer_enabled=True)
                if trigger_after is not None and callable(trigger_after):
                    trigger_after(snapshot)
                # print(is_Successful, type(frame), frame.shape)
                
                if not is_Successful:
                    self.logger.debug(
                        "stream_Start get NOT successful frame. 'camera_Recovery' calling...")
                    self.camera_Recovery(
                        trigger_quit=trigger_quit, 
                        trigger_pause=trigger_pause
                    )
                if number_of_snapshot > 0:
                    number_of_snapshot -= 1
            else:
                self.logger.debug(
                    "stream_Start get trigger_pause. Waiting {} sec.".format(pause_Delay)
                )
                sleep(pause_Delay)

            if trigger_quit is not None and not self.__instance_Exit_Statement:
                if trigger_quit():
                    self.logger.debug(
                        "stream_Start quit trigger activated! Quitting...")
                    self.quit()
                    return 0  # break # Lets make it clear at quit statement
            elif self.__instance_Exit_Statement:
                self.logger.debug("{}-{} Camera Instance stream_Start Exit Statement activated! Quitting...".format(
                        self.flag_Camera,
                        self.instance_id
                    )
                )
                return 0  # break # Lets make it clear at quit statement
            # stdo(1, "Buffer: {}".format(len(self.__buffer_Stream)))
            sleep(delay)
        return 0

    '''
    This code is a function that takes in the camera object and returns an image.
    The code will check if there are any frames in the buffer, if so it will pop one frame from the buffer and return it to be displayed on screen.
    If not then it will wait for a new frame to arrive by calling self.__buffer_Stream.get() which blocks until a new frame arrives or until timeout of 1 second occurs (if no frames have arrived).
    - generated by stenography autopilot 
    '''

    def stream_Connector(self, connection, trigger_pause=None, trigger_quit=None, number_of_snapshot=-1, auto_pop=True, pass_broken=True, delay=0.001):
        if trigger_pause is None or not callable(trigger_pause):
            trigger_pause = self.trigger_pause
            
        pause_Delay = 1
        while number_of_snapshot != 0 and trigger_pause():
            if len(self.__buffer_Stream) > 0:
                # call ui.set_display function that given frame-buffer as parameter

                frame = self.__buffer_Stream.pop() if auto_pop else self.__buffer_Stream.get_Last()

                if not pass_broken:
                    self.logger.debug("stream_Connector get frame!")
                    connection(frame)
                else:
                    self.logger.debug("stream_Connector get broken frame!")
                    if frame is not None:
                        if len(frame.shape) == 3:
                            if frame.shape[2] == 3:
                                self.logger.debug(
                                    "stream_Connector Broken frame has 3 channel, sending to connection"
                                )
                                connection(frame)
                            else:
                                self.logger.debug(
                                    "stream_Connector Broken frame passing..."
                                )
                        else:
                            self.logger.debug(
                                "stream_Connector Broken frame passing..."
                            )
                    else:
                        self.logger.debug(
                            "stream_Connector None frame passing..."
                        )

                if number_of_snapshot > 0:
                    number_of_snapshot -= 1

            if trigger_quit is not None:
                if trigger_quit():
                    self.logger.debug(
                        "stream_Connector quit trigger activated! Breaking the loop...")
                    # self.quit()
                    break
            elif self.__instance_Exit_Statement:
                self.logger.debug(
                    "{}-{} Camera Instance stream_Start Exit Statement activated! Quitting...".format(
                        self.flag_Camera,
                        self.instance_id
                    )
                )
                return 0  # break # Lets make it clear at quit statement
            sleep(delay)
        else:
            if trigger_pause():
                self.logger.debug(
                    "stream_Connector get trigger_pause. Waiting {} sec.".format(pause_Delay)
                )
                # sleep(pause_Delay)
        return 0

    '''
    This code is a simple function that returns the last frame in the buffer.
    If there are no frames, it will return None.
    The code block checks if there are any frames in the buffer and then pops them off of the stack or gets the last one depending on whether auto_pop is set to True or False. If pass_broken is set to True, this function will also check for broken frames and not return them unless they have 3 channels (RGB).
    - generated by stenography autopilot 
    '''

    def stream_Returner(self, auto_pop=False, pass_broken=True):
        if len(self.__buffer_Stream) > 0:
            frame = self.__buffer_Stream.pop() if auto_pop else self.__buffer_Stream.get_Last()
            if pass_broken and frame is not None:
                if len(frame.shape) == 3:
                    if frame.shape[2] == 3:
                        return frame
                    else:
                        self.logger.debug(
                            "stream_Connector Broken frame has less than 3 channel, passing..."
                        )
                else:
                    self.logger.debug(
                        "stream_Connector Broken frame passing..."
                    )
            else:
                return frame
        else:
            return None

    '''
    This code is checking if the camera is active. If it\'s not, then we can\'t get a frame from it.
    If the camera is active, then we try to get a frame from it and return True or False depending on whether that was successful or not.
    - generated by stenography autopilot 
    '''

    def is_Camera_Active(self):
        if self.flag_Camera is CAMERA_FLAGS.BAUMER:
            self.camera_Last_Statement, _ = self.snapshot(True)

            if self.camera_Last_Statement:
                self.logger.debug(
                    "is_Camera_Active get successfully frame from BAUMER Camera. Returning True...")
                return self.camera_Last_Statement
            else:
                self.logger.debug(
                    "is_Camera_Active get NOT successful frame from BAUMER Camera. Returning False...")
                return self.camera_Last_Statement
        elif self.flag_Camera is CAMERA_FLAGS.BASLER:
            # Returns (False, None) in fail, (True, image) otherwise

            self.camera_Last_Statement = False if self.instance_Camera is None else True
            #self.instance_Camera.Open()
            #self.camera_Last_Statement = True

            if self.camera_Last_Statement:
                self.logger.debug(
                    "is_Camera_Active get True from BASLER Camera Control. Returning True...")
                return self.camera_Last_Statement
            else:
                self.logger.debug(
                    "is_Camera_Active get True from BASLER Camera Control. Returning False...")
                return self.camera_Last_Statement
        elif self.flag_Camera is CAMERA_FLAGS.CV2:
            # Returns (False, None) in fail, (True, image) otherwise
            self.camera_Last_Statement = self.instance_Camera.isOpened() if self.instance_Camera is not None else False
            if self.camera_Last_Statement:
                self.logger.debug(
                    "is_Camera_Active get True from CV2 Camera Control. Returning True...")
                return self.camera_Last_Statement
            else:
                self.logger.debug(
                    "is_Camera_Active get True from CV2 Camera Control. Returning False...")
                return self.camera_Last_Statement
        """
        if self.is_instance:
            self.logger.debug("is_Camera_Active get False from is_instance. Returning False...")
            self.camera_Last_Statement = False
            return self.camera_Last_Statement
        """

        self.logger.error(
            "is_Camera_Active returning False at the end of control. Unplanned situation!"
        )
        self.camera_Last_Statement = False
        return self.camera_Last_Statement

    '''
    This code is checking if the camera is active. If it\'s not, then it will try to initialize the camera again.
    If that fails, then it will check for a quit trigger and return None if one exists.
    If there isn\'t a quit trigger, then this code checks for an exit statement in the instance of Camera_Object and returns 0 (break) if one exists.
    - generated by stenography autopilot 
    '''

    def camera_Recovery(self, trigger_quit=None, trigger_pause=None, delay=1):
        if trigger_pause is None or not callable(trigger_pause):
            trigger_pause = self.trigger_pause

        #while not trigger_pause():
        while trigger_pause():
            self.camera_Releaser()
            # Call create instance with lock_until_done = True for handling infinite loop problem
            # self.initialize(index_device = self.index_device, lock_until_done=False)
            self.initialize(
                auto_configure=self.auto_configure,
                extra_params=self.extra_params,
                index_device=self.index_device,
                trigger_quit=trigger_quit,
                trigger_pause=trigger_pause,
                lock_until_done=False,
                exposure_time=self.exposure_time,
                acquisition_framerate_enable=self.acquisition_framerate_enable,
                acquisition_framerate=self.acquisition_framerate
            )
            self.api_Set_Camera_Size(self.resolution)
            if not self.auto_configure:
                pass
            if self.is_Camera_Active():
                self.logger.debug(
                    "camera_Recovery get Camera active. Breaking the loop")
                break

            if trigger_quit is not None:
                if trigger_quit():
                    self.logger.debug(
                        "camera_Recovery quit trigger activated! Returning None...")
                    #self.quit()
                    return None
            elif self.__instance_Exit_Statement:
                self.logger.debug("{}-{} Camera Instance stream_Start Exit Statement activated! Quitting...".format(
                    self.flag_Camera,
                    self.instance_id
                )
                )
                return 0  # break # Lets make it clear at quit statement
            sleep(delay)

    '''
    This code is releasing the camera.
    - generated by stenography autopilot 
    '''

    def camera_Releaser(self):
        #self.logger.debug("camera_Releaser is releasing the camera...")
        if self.instance_Camera is None:
            self.logger.debug("camera_Releaser instance_Camera is None...")
        elif self.flag_Camera is CAMERA_FLAGS.CV2:
            self.instance_Camera.release()
            self.logger.debug("camera_Releaser CV2 Camera is released...")
        elif self.flag_Camera is CAMERA_FLAGS.BASLER:
            if self.instance_Camera.IsGrabbing():
                self.instance_Camera.StopGrabbing()
            self.instance_Camera.Close()
            self.logger.debug("camera_Releaser BASLER Camera is released...")
        else:
            self.logger.debug("camera_Releaser No need action...")
        return 0

    '''
    This code is setting the exposure time of the camera.
    The code block uses if/elif/else statements to determine which camera is being used and then calls a function in that class to set the exposure time.
    - generated by stenography autopilot 
    '''

    def set_Exposure_Time(self, value):
        if self.flag_Camera is CAMERA_FLAGS.BAUMER:
            self.baumer_Set_Camera_Exposure(value)
        elif self.flag_Camera is CAMERA_FLAGS.BASLER:
            self.basler_Set_Camera_Exposure(value)
        elif self.flag_Camera is CAMERA_FLAGS.CV2:
            self.cv2_Set_Camera_Exposure(value)
    
    '''
    This code is setting the exposure time, acquisition framerate enable and acquisition framerate.
    The code block will crash if you set a value that is not in the range of 0 to 65535. 
    This can be fixed by adding an if statement with a boolean variable called "crash_protection" which will check for this condition and return an error message if it\'s true.
    - generated by stenography autopilot 
    '''

    def api_Baumer_Camera_Configurations(self, exposure_time=60000, acquisition_framerate_enable=True, acquisition_framerate=25, crash_protection = False):
        self.baumer_Camera_Configurations_Protected(
            exposure_time = exposure_time, 
            acquisition_framerate_enable= acquisition_framerate_enable, 
            acquisition_framerate=acquisition_framerate
        ) if crash_protection else self.baumer_Camera_Configurations(
            exposure_time=exposure_time,
            acquisition_framerate_enable=acquisition_framerate_enable,
            acquisition_framerate=acquisition_framerate
        )
       
    '''
    This code is setting the exposure time, enabling or disabling the acquisition framerate and setting the frame rate.
    - generated by stenography autopilot 
    '''

    def api_Basler_Camera_Configurations(self, exposure_time=60000, acquisition_framerate_enable=True, acquisition_framerate=25, crash_protection=False):
        self.basler_Camera_Configurations_Protected(
            exposure_time=exposure_time,
            acquisition_framerate_enable=acquisition_framerate_enable,
            acquisition_framerate=acquisition_framerate
        ) if crash_protection else self.basler_Camera_Configurations(
            exposure_time=exposure_time,
            acquisition_framerate_enable=acquisition_framerate_enable,
            acquisition_framerate=acquisition_framerate
        )

    def api_Set_Camera_Size(self, resolution=(1280,720)):
        self.resolution = resolution
        if self.flag_Camera is CAMERA_FLAGS.BAUMER:
            pass
        elif self.flag_Camera is CAMERA_FLAGS.BASLER:
            pass
        elif self.flag_Camera is CAMERA_FLAGS.CV2:
            self.cv2_Set_Camera_Size(self.resolution)
            

    def cv2_Set_Camera_Size(self, resolution):
        if self.instance_Camera is not None:
            self.instance_Camera.set(cv2.CAP_PROP_FRAME_WIDTH, resolution[0]) 
            self.instance_Camera.set(cv2.CAP_PROP_FRAME_HEIGHT, resolution[1]) 
    
    def api_Set_Camera_FPS(self, FPS=25):
        if self.flag_Camera is CAMERA_FLAGS.BAUMER:
            pass
        elif self.flag_Camera is CAMERA_FLAGS.BASLER:
            pass
        elif self.flag_Camera is CAMERA_FLAGS.CV2:
            self.cv2_Set_Camera_FPS(FPS)
  
    def cv2_Set_Camera_FPS(self, FPS):
        if self.instance_Camera is not None:
            self.instance_Camera.set(cv2.CAP_PROP_FPS, FPS)

    # ### ### ### #
    # ### ### ### #
    # ### ### ### #

    # ### ### ### ### ### ### #
    # THIRD PARTY CAMERA APIs #
    # ### ### ### ### ### ### #
    
    '''
    This code is creating a new instance of the camera.
    The index_device parameter is used to specify which device we want to use, in this case it\'s 0 (default).
    If you have more than one camera connected and you want to access another one, just change the value for index_device.
    - generated by stenography autopilot 
    '''

    def api_CV2_Camera_Create_Instance(self, index_device = 0, extra_params = [cv2.CAP_DSHOW]):
        try:
            self.index_device = index_device
            # self.instance_Camera = cv2.VideoCapture(index_device)
            # TODO: Recovery is not working for CV2 camera, check what we need for re-initialization and what CAP_DSHOW flag stands for
            self.instance_Camera = cv2.VideoCapture(
                self.index_device,
                *extra_params
            )
            # self.is_Camera_Initialized = True
        except Exception as error:
            self.logger.error(
                f"{self.flag_Camera} Camera Instance Creation Error: {error}"
            )
            self.is_Camera_Initialized = False

    '''
    This code is creating a new instance of the neoapi.Cam class and assigning it to self.instance_Camera
    This code will only run if there are no errors in importing the module \'neoapi\'. If there is an error, then this code will not be executed and self.
    - generated by stenography autopilot 
    '''

    def api_Baumer_Camera_Create_Instance(self):
        global neoapi
        try:
            # https://docs.python.org/3/tutorial/modules.html#standard-modules
            # https://docs.python.org/3/library/os.path.html#os.path.expanduser
            import sys

            os_name = get_OS()

            # Cross Platform - Source Code
            if os_name == "Windows":
                sys.path.append("neoapi/windows")

            elif os_name == "Linux":
                sys.path.append("neoapi/linux")

            else:
                print("No compatible neoapi library for", os_name, "OS")

            import neoapi
            self.instance_Camera = neoapi.Cam()
        except Exception as error:
            self.logger.error(
                f"{self.flag_Camera} Camera Instance Creation Error: {error}"
            )
            self.is_Camera_Initialized = False

    '''
    This code is creating a global variable called `instance_Camera` and assigning it to the first camera found in the system.
    - generated by stenography autopilot 
    '''

    def api_Basler_Camera_Create_Instance(self):
        global pylon
        try:
            from pypylon import pylon
            self.instance_Camera = pylon.InstantCamera(
                pylon.TlFactory.GetInstance().CreateFirstDevice()
            )
        except Exception as error:
            self.logger.error(
                f"{self.flag_Camera} Camera Instance Creation Error: {error}"
            )
            self.is_Camera_Initialized = False
    
    def api_Arducam_Camera_Create_Instance(self):
        global ArducamSDK
        try:
            import arducam_config_parser
            import ArducamSDK
            self.is_Camera_Initialized, self.instance_Camera = self.arducam_Camera_initFromFile(
                ""
            )
        except Exception as error:
            self.logger.error(
                f"{self.flag_Camera} Camera Instance Creation Error: {error}"
            )
            self.is_Camera_Initialized = False
    
    '''
    This code is setting the pixel format to BGR8. This means that the camera will return a 3 channel image, with each channel being 8 bits wide.
    - generated by stenography autopilot 
    '''

    def api_Baumer_Camera_Is_Colorful(self):
        if self.instance_Camera is not None:
            self.logger.info("Pixel Format list is {}".format(self.instance_Camera.f.PixelFormat.GetString()))

            try:
                if self.instance_Camera.f.PixelFormat.GetEnumValueList().IsReadable("BGR8"):
                    self.is_colored = True
                    self.instance_Camera.f.PixelFormat.SetString("BGR8")
                elif self.instance_Camera.f.PixelFormat.GetEnumValueList().IsReadable("Mono8"):
                    self.instance_Camera.f.PixelFormat.SetString("Mono8")
                    self.is_colored = False
                else:
                    self.logger.error("BAUMER Camera: Error, no supported pixel format")
                    return -1
                return self.is_colored
            except neoapi.FeatureAccessException as error:
                self.logger.error(
                    "BAUMER Camera api_Baumer_Camera_Is_Colorful FeatureAccessException: {}".format(error)
                )
                self.is_Camera_Initialized = False
            except Exception as error:
                self.logger.error("BAUMER Camera api_Baumer_Camera_Is_Colorful Exception: {}".format(error))
                self.is_Camera_Initialized = False
 
    '''
    This code is setting the exposure time, acquisition frame rate enable and acquisition frame rate.
    The code also sets the color transformation to continuous. This is because we want to keep our images in RGB format.
    This way we can use opencv\'s cvtColor function which converts an image from one color space into another.
    - generated by stenography autopilot 
    '''

    def baumer_Camera_Configurations_Protected(self, exposure_time=60000, acquisition_framerate_enable=True, acquisition_framerate=25):
        if self.instance_Camera is not None:
            #self.instance_Camera.f.ExposureAuto.Set(True)
            try:
                self.instance_Camera.f.ColorTransformationAuto.SetString("Continuous")
                self.set_Exposure_Time(exposure_time)
                #self.instance_Camera.f.ExposureTime.Set(exposure_time)
                self.instance_Camera.f.AcquisitionFrameRateEnable.value = acquisition_framerate_enable
                self.instance_Camera.f.AcquisitionFrameRate.value = acquisition_framerate
                self.is_Camera_Initialized = True
            except neoapi.FeatureAccessException as error:
                self.logger.error("BAUMER Camera api_Baumer_Camera_Configurations FeatureAccessException: {}".format(error))
                self.is_Camera_Initialized = False
            except Exception as error:
                self.logger.error("BAUMER Camera api_Baumer_Camera_Configurations Exception: {}".format(error))
                self.is_Camera_Initialized = False

            self.logger.info(
                "BAUMER Camera: Exposure Time is '{}', Acquisition Frame Rate Enable is '{}', Acquisition Frame Rate is '{}'".format(
                    self.instance_Camera.f.ExposureTime.Get(),  # exposure_time,
                    self.instance_Camera.f.AcquisitionFrameRateEnable.value,
                    self.instance_Camera.f.AcquisitionFrameRate.value
                )
            )
            sleep(3)
        return 0
        
    '''
    This code is setting the exposure time, acquisition frame rate enable and acquisition frame rate.
    The code also sets the color transformation to continuous mode. This means that when you take a picture, it will be in RGB format.
    This is important because we are using OpenCV to process images later on in our pipeline. If we were not doing this, then we would have to convert each image into BGR format before processing it with OpenCV functions like cv2.imshow().
    - generated by stenography autopilot 
    '''

    def baumer_Camera_Configurations(self, exposure_time=60000, acquisition_framerate_enable=True, acquisition_framerate=25):
        if self.instance_Camera is not None:
            #self.instance_Camera.f.ExposureAuto.Set(True)
            self.instance_Camera.f.ColorTransformationAuto.SetString("Continuous")
            self.set_Exposure_Time(exposure_time)
            # self.instance_Camera.f.ExposureTime.Set(exposure_time)
            self.instance_Camera.f.AcquisitionFrameRateEnable.value = acquisition_framerate_enable
            self.instance_Camera.f.AcquisitionFrameRate.value = acquisition_framerate

            self.logger.info(
                "BAUMER Camera: Exposure Time is '{}', Acquisition Frame Rate Enable is '{}', Acquisition Frame Rate is '{}'".format(
                    self.instance_Camera.f.ExposureTime.Get(),  # exposure_time,
                    self.instance_Camera.f.AcquisitionFrameRateEnable.value,
                    self.instance_Camera.f.AcquisitionFrameRate.value
                )
            )
            self.is_Camera_Initialized = True
        else:
            self.is_Camera_Initialized = False
        sleep(3)
        return 0

    '''
    This code is setting the exposure time of the camera.
    - generated by stenography autopilot 
    '''

    def basler_Camera_Configurations_Protected(self, exposure_time=60000, acquisition_framerate_enable=True, acquisition_framerate=25):
        if self.instance_Camera is not None:
            try:
                self.instance_Camera.Open()

                self.converter = pylon.ImageFormatConverter()
                self.converter.OutputPixelFormat = pylon.PixelType_BGR8packed
                self.converter.OutputBitAlignment = pylon.OutputBitAlignment_MsbAligned

                self.set_Exposure_Time(exposure_time)
                #self.instance_Camera.ExposureTime.SetValue(exposure_time)

                if not self.instance_Camera.IsGrabbing():
                    self.instance_Camera.StartGrabbing(pylon.GrabStrategy_LatestImageOnly)
                
            except Exception as error:
                self.logger.error("BAUMER Camera api_Baumer_Camera_Configurations Exception: {}".format(error))
                self.is_Camera_Initialized = False
                    
            self.logger.info(
                "BAUMER Camera: Model Name is '{}', Exposure Time is is '{}'".format(
                    self.instance_Camera.GetDeviceInfo().GetModelName(),
                    self.instance_Camera.ExposureTime.GetValue()  # exposure_time,
                )
            )
            self.is_Camera_Initialized = True
        else:
            self.is_Camera_Initialized = False

    '''
    This code is setting the exposure time of the camera to 60000 microseconds.
    The code also sets whether or not acquisition framerate should be enabled and what that value should be.
    This is done by calling a function in this class called set_Exposure_Time(). This function takes two arguments, 
    the first being the desired exposure time and the second being a boolean variable which determines if acquisition framerate should be enabled or disabled. The default value for this argument is True (enabled).
    - generated by stenography autopilot 
    '''

    def basler_Camera_Configurations(self, exposure_time=60000, acquisition_framerate_enable=True, acquisition_framerate=25):
        if self.instance_Camera is not None:
            self.instance_Camera.Open()

            self.converter = pylon.ImageFormatConverter()
            self.converter.OutputPixelFormat = pylon.PixelType_BGR8packed
            self.converter.OutputBitAlignment = pylon.OutputBitAlignment_MsbAligned

            self.set_Exposure_Time(exposure_time)
            #self.instance_Camera.ExposureTime.SetValue(exposure_time)

            if not self.instance_Camera.IsGrabbing():
                self.instance_Camera.StartGrabbing(pylon.GrabStrategy_LatestImageOnly)
                
            self.logger.info(
                "BAUMER Camera: Model Name is '{}', Exposure Time is is '{}'".format(
                    self.instance_Camera.GetDeviceInfo().GetModelName(),
                    self.instance_Camera.ExposureTime.GetValue()  # exposure_time,
                )
            )
            self.is_Camera_Initialized = True
        else:
            self.is_Camera_Initialized = False

    def baumer_Set_Camera_Exposure(self, value):
        if self.instance_Camera is not None:
            self.instance_Camera.f.ExposureTime.Set(value)

    def basler_Set_Camera_Exposure(self, value):
        if self.instance_Camera is not None:
            self.instance_Camera.ExposureTime.SetValue(value)

    '''
    This code is setting the exposure time of the camera.
    The value 3 means that it will be set to 640 ms (640 µs).
    This is a good value for my camera, but you can change this if you want.
    - generated by stenography autopilot 
    '''

    def cv2_Set_Camera_Exposure(self, value):
        """
        # https://www.principiaprogramatica.com/2017/06/11/setting-manual-exposure-in-opencv/
        CAP_PROP_EXPOSURE	Exposure Time
        -1              	640 ms
        -2              	320 ms
        -3              	160 ms
        -4              	80 ms
        -5              	40 ms
        -6              	20 ms
        -7              	10 ms
        -8              	5 ms
        -9              	2.5 ms
        -10              	1.25 ms
        -11              	650 µs
        -12              	312 µs
        -13              	150 µs
        
        # self.instance_Camera.set(cv2.CAP_PROP_FPS, -3)
        """
        if self.instance_Camera is not None:
            self.instance_Camera.set(cv2.CAP_PROP_EXPOSURE, value)
    
    '''
    This code is getting the list of available camera sizes.
    - generated by stenography autopilot 
    '''

    def baumer_Camera_Size(self):
        """
        print("self.instance_Camera.f:", self.instance_Camera.f)
        print("self.instance_Camera.f:",
              self.instance_Camera.f.GetEnumValueList()
        )
        """
        pass
    
    def basler_Camera_Size(self):
        pass
    
    def cv2_Camera_Size(self):
        pass
    
    def arducam_Camera_initFromFile(self, fileName):
        # global cfg, handle, Width, Height, color_mode, save_raw
        #load config file
        # config = json.load(open(fileName,"r"))
        config = arducam_config_parser.LoadConfigFile(fileName)

        camera_parameter = config.camera_param.getdict()
        Width = camera_parameter["WIDTH"]
        Height = camera_parameter["HEIGHT"]

        BitWidth = camera_parameter["BIT_WIDTH"]
        ByteLength = 1
        if BitWidth > 8 and BitWidth <= 16:
            ByteLength = 2
            save_raw = True
        FmtMode = camera_parameter["FORMAT"][0]
        color_mode = camera_parameter["FORMAT"][1]
        print("color mode",color_mode)

        I2CMode = camera_parameter["I2C_MODE"]
        I2cAddr = camera_parameter["I2C_ADDR"]
        TransLvl = camera_parameter["TRANS_LVL"]
        cfg = {"u32CameraType":0x00,
                "u32Width":Width,"u32Height":Height,
                "usbType":0,
                "u8PixelBytes":ByteLength,
                "u16Vid":0,
                "u32Size":0,
                "u8PixelBits":BitWidth,
                "u32I2cAddr":I2cAddr,
                "emI2cMode":I2CMode,
                "emImageFmtMode":FmtMode,
                "u32TransLvl":TransLvl }

        #ret,handle,rtn_cfg = ArducamSDK.Py_ArduCam_open(cfg,0)
        ret, handle, rtn_cfg = ArducamSDK.Py_ArduCam_autoopen(cfg)
        if ret == 0:
        
            #ArducamSDK.Py_ArduCam_writeReg_8_8(handle,0x46,3,0x00)
            usb_version = rtn_cfg['usbType']
            configs = config.configs
            configs_length = config.configs_length
            for i in range(configs_length):
                type = configs[i].type
                if ((type >> 16) & 0xFF) != 0 and ((type >> 16) & 0xFF) != usb_version:
                    continue
                if type & 0xFFFF == arducam_config_parser.CONFIG_TYPE_REG:
                    ArducamSDK.Py_ArduCam_writeSensorReg(handle, configs[i].params[0], configs[i].params[1])
                elif type & 0xFFFF == arducam_config_parser.CONFIG_TYPE_DELAY:
                    time.sleep(float(configs[i].params[0])/1000)
                elif type & 0xFFFF == arducam_config_parser.CONFIG_TYPE_VRCMD:
                    configBoard(configs[i])

            ArducamSDK.Py_ArduCam_registerCtrls(handle, config.controls, config.controls_length)
            # ArducamSDK.Py_ArduCam_setCtrl(handle, "setFramerate", 5)
            # ArducamSDK.Py_ArduCam_setCtrl(handle, "setExposure", 5)
            # ArducamSDK.Py_ArduCam_setCtrl(handle, "setExposureTime", 33000)
            # ArducamSDK.Py_ArduCam_setCtrl(handle, "setGain", 5)
            # ArducamSDK.Py_ArduCam_setCtrl(handle, "setAnalogueGain", 100)

            rtn_val,datas = ArducamSDK.Py_ArduCam_readUserData(handle,0x400-16, 16)
            print("Serial: %c%c%c%c-%c%c%c%c-%c%c%c%c"%(datas[0],datas[1],datas[2],datas[3],
                                                        datas[4],datas[5],datas[6],datas[7],
                                                        datas[8],datas[9],datas[10],datas[11]))

            return True, handle
        else:
            print("open fail,rtn_val = ", ret)
            return False, handle

        
    # ### ### ### ### ### ### #
    # ### ### ### ### ### ### #
    # ### ### ### ### ### ### #
    
    # ### ### ### ### ### #
    # ### BUFFER APIs ### #
    # ### ### ### ### ### #

    @staticmethod
    def is_Same_Image(image_one, image_two):
        return True if image_one == image_two else False
    
    def set_Buffer_Size(self, size):
        self.__buffer_Stream.update_Buffer_Size(size)
    
    def get_Buffer_Size(self):
        return len(self.__buffer_Stream)
        
    '''
    This code is getting the image from the buffer stream.
    If there are no images in the buffer, it will return None.
    - generated by stenography autopilot 
    '''

    def get_Buffered_Image(self, index=0):
        return self.__buffer_Stream.get(index) if len(self.__buffer_Stream) > index else None
    
    '''
    This code is clearing the buffer.
    - generated by stenography autopilot 
    '''

    def buffer_Clear(self):
        self.logger.debug("buffer_Clear Buffer is cleaning...")
        return self.__buffer_Stream.clear()

    '''
    This code is setting the buffer to a custom structure.
    - generated by stenography autopilot 
    '''

    def buffer_Connector(self, custom_buffer):
        if type(custom_buffer) is Structure_Buffer:
            self.__buffer_Stream = custom_buffer

    def buffer_information_text_Connector(self, connector):
        connector(self.get_information())
    
    # ### ### ### ### ### #
    # ### ### ### ### ### #
    # ### ### ### ### ### #
    
    # ### ### ## ### ### #
    # ### OTHER APIs ### #
    # ### ### ## ### ### #

    '''
    This code is getting information from the camera. It\'s a dictionary of all the variables that are being used in this class.
    The code block below gets the values for each variable and puts them into a dictionary, which then returns it as text or both text and dict.
    If you want to get only one value, just put its name in filter_keys (e.g., "flag_Camera"). If you want to rename it, use rename (e.g.
    - generated by stenography autopilot 
    '''

    def get_information(self, filter_keys=None, rename=None, return_only_text=True, return_only_dict=True, text_format="{}:{}", ends="\n"):
        dict_information = dict()
        temp_text = ""
    
        dict_information["flag_Camera"] = self.flag_Camera
        dict_information["verbose_level"] = self.verbose_level
        dict_information["is_Camera_Initialized"] = int(self.is_Camera_Initialized)
        dict_information["is_Camera_Active"] = int(self.camera_Last_Statement)
        dict_information["buffer_max"] = self.__buffer_Stream.max_limit
        dict_information["buffer_len"] = len(self.__buffer_Stream)
        
        if filter_keys is not None:
            swap_dict_information = dict()

            if rename is not None:
                for index, filter_key in enumerate(filter_keys):
                    swap_dict_information[rename[index]] = dict_information[filter_key]
            else:
                for filter_key in filter_keys:
                    swap_dict_information[filter_key] = dict_information[filter_key]
                
            dict_information = swap_dict_information

        if return_only_text or not return_only_dict:
            for key, value in dict_information.items():
                temp_text += text_format.format(str(key), str(value)) + ends

        if return_only_text:
            return temp_text
        else:
            if return_only_dict:
                return dict_information
            else:
                return temp_text, dict_information

    def get_Is_Object_Initialized(self):
        return self.is_Object_Initialized
    
    def get_Is_Camera_Initialized(self):
        return self.is_Camera_Initialized

    # ### ### ## ### ### #
    # ### ### ## ### ### #
    # ### ### ## ### ### #
